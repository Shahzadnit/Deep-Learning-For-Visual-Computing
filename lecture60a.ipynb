{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 60: Activity recognition using CNN-LSTM\n",
    "## 60a: Train CNN for activity classification\n",
    "\n",
    "#### Note:\n",
    "      1. Run lecture59_preProc1.ipynb before running executing this notebook\n",
    "      2. Files lecture60a.ipynb, lecture60b.ipynb, lecture60c.ipynb are part of the same tutorial and are to be exeuted sequentially  \n",
    "#### Dataset: [UCF101](http://crcv.ucf.edu/data/UCF101.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms,datasets, models\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "# import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check availability of GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    pinMem = True\n",
    "else:\n",
    "    pinMem = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from folder using ImageFolder\n",
    "trainDir = 'train_5class'\n",
    "valDir = 'test_5class'\n",
    "apply_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "# Training dataloader\n",
    "train_dataset = datasets.ImageFolder(trainDir,transform=apply_transform)\n",
    "trainLoader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True,num_workers=4, pin_memory=pinMem)\n",
    "\n",
    "# Test dataloader\n",
    "test_dataset = datasets.ImageFolder(valDir,transform=apply_transform)\n",
    "testLoader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False,num_workers=4, pin_memory=pinMem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of train and test datasets\n",
    "print('No. of samples in train set: '+str(len(trainLoader.dataset)))\n",
    "print('No. of samples in test set: '+str(len(testLoader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counting number of trainable parameters\n",
    "totalParams = 0\n",
    "for params in net.parameters():\n",
    "    print(params.size())\n",
    "    totalParams += np.sum(np.prod(params.size()))\n",
    "print('Total number of parameters: '+str(totalParams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the last fully-connected layer for 5 classes\n",
    "net.fc = nn.Linear(512,5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    print('GPU is available!')   \n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss() # Negative Log-likelihood\n",
    "optimizer = optim.Adam(net.fc.parameters(), lr=1e-4) # Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = 10\n",
    "\n",
    "trainLoss = []\n",
    "trainAcc = []\n",
    "testLoss = []\n",
    "testAcc = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(iterations):\n",
    "    epochStart = time.time()\n",
    "    runningLoss = 0.0   \n",
    "    avgTotalLoss = 0.0\n",
    "    running_correct = 0   \n",
    "    \n",
    "    net.train(True) # For training \n",
    "    batchNum = 1\n",
    "    for data in trainLoader:\n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)            \n",
    "            running_correct += (predicted.cpu() == labels.data.cpu()).sum()           \n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            running_correct += (predicted == labels.data).sum()            \n",
    "       \n",
    "        # Initialize gradients to zero\n",
    "        optimizer.zero_grad()             \n",
    "        \n",
    "        # Compute loss/error\n",
    "        loss = criterion(F.log_softmax(outputs), labels)\n",
    "        # Backpropagate loss and compute gradients\n",
    "        loss.backward()\n",
    "        # Update the network parameters\n",
    "        optimizer.step()\n",
    "        # Accumulate loss per batch\n",
    "        runningLoss += loss.data[0]   \n",
    "        batchNum += 1\n",
    "\n",
    "    avgTrainAcc = running_correct/float(len(trainLoader.dataset))\n",
    "    avgTrainLoss = runningLoss/float(len(trainLoader.dataset))    \n",
    "    trainAcc.append(avgTrainAcc)\n",
    "    trainLoss.append(avgTrainLoss)  \n",
    "    \n",
    "    # Evaluating performance on test set for each epoch\n",
    "    net.train(False) # For testing [Affects batch-norm and dropout layers (if any)]\n",
    "    running_correct = 0 \n",
    "    for data in testLoader:\n",
    "        inputs,labels = data\n",
    "        # Wrap them in Variable\n",
    "        if use_gpu:\n",
    "            inputs, labels= Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)            \n",
    "            running_correct += (predicted.cpu() == labels.data.cpu()).sum()\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "            # Model 1\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            running_correct += (predicted == labels.data).sum()\n",
    "        \n",
    "        loss = criterion(F.log_softmax(outputs), labels)\n",
    "        \n",
    "        runningLoss += loss.data[0]  \n",
    "\n",
    "    avgTestLoss = runningLoss/float(len(testLoader.dataset))\n",
    "    avgTestAcc = running_correct/float(len(testLoader.dataset))\n",
    "    testAcc.append(avgTestAcc)  \n",
    "    testLoss.append(avgTestLoss)\n",
    "    \n",
    "    # Plotting training loss vs Epochs\n",
    "    fig1 = plt.figure(1)        \n",
    "    plt.plot(range(epoch+1),trainLoss,'r-',label='train')  \n",
    "    plt.plot(range(epoch+1),testLoss,'g-',label='test') \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')   \n",
    "    # Plotting testing accuracy vs Epochs\n",
    "    fig2 = plt.figure(2)        \n",
    "    plt.plot(range(epoch+1),trainAcc,'r-',label='train')    \n",
    "    plt.plot(range(epoch+1),testAcc,'g-',label='test')        \n",
    "    if epoch==0:\n",
    "        plt.legend(loc='upper left')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')  \n",
    "        \n",
    "  \n",
    "        \n",
    "    epochEnd = time.time()-epochStart\n",
    "    print('Iteration: {:.0f} /{:.0f};  Training Loss: {:.6f} ; Training Acc: {:.3f}'\\\n",
    "          .format(epoch + 1,iterations,avgTrainLoss,avgTrainAcc*100))\n",
    "    print('Iteration: {:.0f} /{:.0f};  Testing Loss: {:.6f} ; Testing Acc: {:.3f}'\\\n",
    "          .format(epoch + 1,iterations,avgTestLoss,avgTestAcc*100))\n",
    "   \n",
    "    print('Time consumed: {:.0f}m {:.0f}s'.format(epochEnd//60,epochEnd%60))\n",
    "end = time.time()-start\n",
    "print('Training completed in {:.0f}m {:.0f}s'.format(end//60,end%60))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'resnet18Pre_fcOnly5class_ucf101_10adam_1e-4_b128.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
